name: CI

on: [push, pull_request]

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      BUNDLE_JOBS: 4
      BUNDLE_RETRY: 3
      BUNDLE_PATH: vendor/bundle
      BUNDLE_CLEAN: "true"
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - uses: actions/setup-ruby@v1
        with:
          ruby-version: "2.6"

      # Ruby dependencies
      - name: Bundle Cache
        uses: actions/cache@v1
        with:
          path: vendor/bundle
          key: ${{ runner.os }}-gems-${{ hashFiles('**/Gemfile.lock') }}
          restore-keys: |
            ${{ runner.os }}-gems-
      - name: Bundle Install
        run: bundle install --frozen

      # Yarn dependencies
      - name: Yarn Cache Path
        id: yarn-cache-dir-path
        run: echo "::set-output name=dir::$(yarn cache dir)"
      - name: Yarn Cache
        uses: actions/cache@v1
        with:
          path: ${{ steps.yarn-cache-dir-path.outputs.dir }}
          key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
          restore-keys: |
            ${{ runner.os }}-yarn-
      - name: Yarn Install
        run: yarn install

      # Build
      - name: Set production DEPLOY_ENV
        if: github.ref == 'refs/heads/master'
        run: echo "::set-env name=DEPLOY_ENV::production"
      - name: Set staging DEPLOY_ENV
        if: github.ref != 'refs/heads/master'
        run: echo "::set-env name=DEPLOY_ENV::staging"
      - name: Build
        env:
          DOCS_API_KEY: ${{ secrets.DOCS_API_KEY }}
        run: bundle exec middleman build --clean --verbose --environment=${{ env.DEPLOY_ENV }}

      # Lint
      - name: Lint
        run: bundle exec rake lint

      # Artifact
      - uses: actions/upload-artifact@v1
        if: success() && (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/staging')
        with:
          name: build
          path: ./build

      # Push production builds to "build-history" branch to maintain history of
      # built and deployed versions.
      - name: Commit Build History
        if: success() && github.ref == 'refs/heads/master'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: yarn run gh-pages --dist ./build/ --branch build-history --user "$GITHUB_ACTOR <$GITHUB_ACTOR@users.noreply.github.com>" --repo "https://${GITHUB_ACTOR}:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git"

  deploy:
    if: success() && (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/staging')
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: "3.8"
      - uses: dschep/install-pipenv-action@v1

      # Python deployment dependencies
      - name: Pipenv Cache
        uses: actions/cache@v1
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}
          restore-keys: |
            ${{ runner.os }}-pipenv-
      - name: Pipenv Install
        run: pipenv install --deploy

      # Deploy to S3 bucket.
      - uses: actions/download-artifact@v1
        with:
          name: build
          path: ./build
      - name: Set production BUCKET_NAME
        if: github.ref == 'refs/heads/master'
        run: echo "::set-env name=BUCKET_NAME::${{ secrets.PRODUCTION_BUCKET_NAME }}"
      - name: Set staging BUCKET_NAME
        if: github.ref != 'refs/heads/master'
        run: echo "::set-env name=BUCKET_NAME::${{ secrets.STAGING_BUCKET_NAME }}"
      - name: Deploy
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
        run: |
          # Sync all cache-busted assets with long cache-control expirations.
          pipenv run aws s3 sync ./build/ "s3://${BUCKET_NAME}/" \
            --exclude '*' \
            --include 'assets/*' \
            --cache-control 'public, max-age=31536000, immutable'
          # Sync the remaining files, disallowing caching on those.
          pipenv run aws s3 sync ./build/ "s3://${BUCKET_NAME}/" --cache-control 'max-age=0, no-cache, must-revalidate'
          # Run the sync one more time to delete old files. Run this separately
          # since otherwise --deletes occur first:
          # https://github.com/aws/aws-cli/issues/1417
          sleep 5
          pipenv run aws s3 sync ./build/ "s3://${BUCKET_NAME}/" --cache-control 'max-age=0, no-cache, must-revalidate' --delete
